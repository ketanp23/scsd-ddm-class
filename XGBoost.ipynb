{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtsnqyQva25oKQ7szNJmjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketanp23/scsd-ddm-class/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rate (Î·): An important variable that modifies how much each tree contributes to the final prediction. While more trees are needed smaller values frequently result in more accurate models.\n",
        "\n",
        "Max Depth: This parameter controls the depth of every tree, avoiding overfitting and being essential to controlling the model's complexity.\n",
        "\n",
        "Gamma: Based on the decrease in loss it determines when a node in the tree will split. The algorithm becomes more conservative with a higher gamma value hence avoiding splits that don't decreases the loss. It helps in managing tree complexity.\n",
        "\n",
        "Subsample: Manages the percentage of data that is sampled at random to grow each tree hence lowering variance and enhancing generalization. Setting it too low could result in underfitting.\n",
        "\n",
        "Colsample Bytree: Establishes the percentage of features that will be sampled at random for growing each tree.\n",
        "\n",
        "n_estimators: Specifies the number of boosting rounds.\n",
        "\n",
        "alpha (L1 regularization term) and lambda (L2 regularization term) : Control the strength of L1 and L2 regularization respectively. A higher value results in stronger regularization.\n",
        "\n",
        "min_child_weight: Influences the tree structure by controlling the minimum amount of data required to create a new node.\n",
        "\n",
        "scale_pos_weight: Useful in imbalanced class scenarios to control the balance of positive and negative weights."
      ],
      "metadata": {
        "id": "XOuzgIQuISLg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "94RtKDNiINdu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Churn_Modelling_xgboost.csv')\n",
        "X = dataset.iloc[:, 3:13]\n",
        "y = dataset.iloc[:, 13].values\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxNj6XVeIs9v",
        "outputId": "71a1e5ac-4882-4873-c4e1-0919f2138a82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
            "0             619    France  Female   42       2       0.00              1   \n",
            "1             608     Spain  Female   41       1   83807.86              1   \n",
            "2             502    France  Female   42       8  159660.80              3   \n",
            "3             699    France  Female   39       1       0.00              2   \n",
            "4             850     Spain  Female   43       2  125510.82              1   \n",
            "...           ...       ...     ...  ...     ...        ...            ...   \n",
            "9995          771    France    Male   39       5       0.00              2   \n",
            "9996          516    France    Male   35      10   57369.61              1   \n",
            "9997          709    France  Female   36       7       0.00              1   \n",
            "9998          772   Germany    Male   42       3   75075.31              2   \n",
            "9999          792    France  Female   28       4  130142.79              1   \n",
            "\n",
            "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
            "0             1               1        101348.88  \n",
            "1             0               1        112542.58  \n",
            "2             1               0        113931.57  \n",
            "3             0               0         93826.63  \n",
            "4             1               1         79084.10  \n",
            "...         ...             ...              ...  \n",
            "9995          1               0         96270.64  \n",
            "9996          1               1        101699.77  \n",
            "9997          0               1         42085.58  \n",
            "9998          1               0         92888.52  \n",
            "9999          1               0         38190.78  \n",
            "\n",
            "[10000 rows x 10 columns]\n",
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since XGBoost can internally handle categorical features.\n",
        "\n",
        "The code converts the specified columns to the categorical data type.\n",
        "\n",
        "While internally representing categories with integers and categorical type retains the semantic meaning of the categories.\n"
      ],
      "metadata": {
        "id": "OKiMJ-hsJHgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['Geography'] = X['Geography'].astype('category')\n",
        "X['Gender'] = X['Gender'].astype('category')"
      ],
      "metadata": {
        "id": "4RscXlrkJEMj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split our dataset into training and testing for the model training and testing.\n",
        "\n",
        "test_size=0.25: Means 25% test data and 75% train data used.\n",
        "random_state=0: Ensures reproducibility\n",
        "X_train, X_test: Feature sets\n",
        "y_train, y_test: Target labels"
      ],
      "metadata": {
        "id": "5gyZs711JOFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "gzWX4gv4JSgK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will convert our dataset into DMatrix structure. DMatrix is a special data structure in XGBoost for faster training and less memory use.\n",
        "\n",
        "\n",
        "To convert our data to DMatrix format , we will use XGBoost's API. It takes both features and labels.\n",
        "\n",
        "Use enable_categorical = True to handle Pandas categorical columns automatically."
      ],
      "metadata": {
        "id": "TuFHy42sJVRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_train = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
        "xgb_test = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
      ],
      "metadata": {
        "id": "f78KyKbuJZva"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will initialize XGBoost model with hyperparameters like a binary logistic objective, maximum tree depth and learning rate. It then trains the model using the `xgb_train` dataset for 50 boosting rounds.\n",
        "\n",
        "\n",
        "objective: 'binary:logistic' for binary classification\n",
        "max_depth: 3 limits tree depth\n",
        "\n",
        "learning_rate: 0.1 controls step size\n",
        "\n",
        "xgb.train(...) trains the XGBoost model using specified params and training data\n",
        "\n",
        "The specified hyperparameters define the model's structure and training behavior, impacting its accuracy and generalization on the given dataset. Adjusting these hyperparameters are necessary for optimal performance in different scenarios."
      ],
      "metadata": {
        "id": "XKKPpvnXJeA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'max_depth': 3,\n",
        "    'learning_rate': 0.1,\n",
        "}\n",
        "n=50\n",
        "model = xgb.train(params=params,dtrain=xgb_train,num_boost_round=n)"
      ],
      "metadata": {
        "id": "Vx9qbtMhJkLx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will predict labels and then converts the predicted probabilities (preds) to integer labels allowing for a straightforward accuracy comparison with the true labels."
      ],
      "metadata": {
        "id": "hBcLRn9OJpba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(xgb_test)\n",
        "preds = np.round(preds)\n",
        "accuracy= accuracy_score(y_test,preds)\n",
        "print('Accuracy of the model is:', accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giC1D7NnJqsN",
        "outputId": "389c7110-7e06-49ac-f2ea-826b42883720"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is: 86.83999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we achieved a accuracy of 86.6% which is very good meaning our model is working fine with real world dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1AAlFAcJuCV"
      }
    }
  ]
}