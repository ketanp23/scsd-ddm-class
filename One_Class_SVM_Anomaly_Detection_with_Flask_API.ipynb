{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketanp23/scsd-ddm-class/blob/main/One_Class_SVM_Anomaly_Detection_with_Flask_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "End-to-End Anomaly Detection System using One-Class SVM and Flask.\n",
        "\n",
        "This script covers:\n",
        "1.  Synthetic dataset generation (normal vs. anomaly).\n",
        "2.  Model Training using One-Class SVM.\n",
        "3.  Model Testing and Validation with a labeled test set.\n",
        "4.  Model Evaluation (Accuracy, Precision, Recall, F1-Score, Confusion Matrix).\n",
        "5.  Model Serving via a Flask API.\n",
        "\n",
        "Requirements:\n",
        "- scikit-learn\n",
        "- numpy\n",
        "- flask\n",
        "\n",
        "Install with: pip install scikit-learn numpy flask\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# --- Global Configuration ---\n",
        "MODEL_FILE = 'one_class_svm_model.joblib'\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "def create_dataset():\n",
        "    \"\"\"\n",
        "    Creates a synthetic 2D dataset.\n",
        "\n",
        "    - Training data: 200 points from a \"normal\" Gaussian distribution.\n",
        "    - Test data: 100 points (50 normal, 50 anomalies).\n",
        "\n",
        "    Returns:\n",
        "        X_train (np.array): Training data (normal points only).\n",
        "        X_test (np.array): Test data (mixed normal and anomaly).\n",
        "        y_test (np.array): Labels for test data (0=normal, 1=anomaly).\n",
        "    \"\"\"\n",
        "    print(\"Generating synthetic dataset...\")\n",
        "\n",
        "    # 1. Training Data (Normal)\n",
        "    # 200 points centered at (0, 0)\n",
        "    X_train = 0.5 * np.random.randn(200, 2) + np.array([0, 0])\n",
        "\n",
        "    # 2. Test Data (Mixed)\n",
        "    # 50 \"normal\" points, close to the training cluster\n",
        "    X_test_normal = 0.5 * np.random.randn(50, 2) + np.array([0, 0])\n",
        "    y_test_normal = np.zeros(50, dtype=int) # Label 0 for normal\n",
        "\n",
        "    # 50 \"anomaly\" points, far from the training cluster\n",
        "    X_test_anomaly = 4 * np.random.rand(50, 2) - np.array([2, 2])\n",
        "    # Ensure anomalies are spread out, e.g., in all four quadrants\n",
        "    X_test_anomaly[12:25] += np.array([4, 0])\n",
        "    X_test_anomaly[25:37] += np.array([0, 4])\n",
        "    X_test_anomaly[37:50] += np.array([4, 4])\n",
        "    y_test_anomaly = np.ones(50, dtype=int) # Label 1 for anomaly\n",
        "\n",
        "    # Combine test data\n",
        "    X_test = np.vstack((X_test_normal, X_test_anomaly))\n",
        "    y_test = np.concatenate((y_test_normal, y_test_anomaly))\n",
        "\n",
        "    return X_train, X_test, y_test\n",
        "\n",
        "def train_and_evaluate_model():\n",
        "    \"\"\"\n",
        "    Trains, saves, and evaluates the One-Class SVM model.\n",
        "    \"\"\"\n",
        "    X_train, X_test, y_test = create_dataset()\n",
        "\n",
        "    # --- 1. Model Training ---\n",
        "    print(\"Training One-Class SVM model...\")\n",
        "\n",
        "    # Initialize One-Class SVM.\n",
        "    # 'nu' is a key parameter:\n",
        "    # - An upper bound on the fraction of training errors.\n",
        "    # - A lower bound on the fraction of support vectors.\n",
        "    # - We set it to 0.1, assuming ~10% of our training data might be noisy.\n",
        "    svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.1)\n",
        "\n",
        "    # Train the model ONLY on the \"normal\" data.\n",
        "    svm.fit(X_train)\n",
        "\n",
        "    print(f\"Model trained and saved to {MODEL_FILE}\")\n",
        "    joblib.dump(svm, MODEL_FILE)\n",
        "\n",
        "    # --- 2. Model Testing and Validation ---\n",
        "    print(\"\\n--- Model Evaluation ---\")\n",
        "\n",
        "    # Predict on the mixed test set.\n",
        "    # The model returns:\n",
        "    #  1 for inliers (predicted as \"normal\")\n",
        "    # -1 for outliers (predicted as \"anomaly\")\n",
        "    y_pred_raw = svm.predict(X_test)\n",
        "\n",
        "    # --- 3. Model Evaluation Parameters ---\n",
        "\n",
        "    # We need to map the model's output to our ground truth labels:\n",
        "    # Model: -1 (anomaly) -> Our Label: 1 (anomaly)\n",
        "    # Model:  1 (normal)  -> Our Label: 0 (normal)\n",
        "    y_pred = [1 if p == -1 else 0 for p in y_pred_raw]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy:  {accuracy * 100:.2f}%\")\n",
        "    print(f\"Precision: {precision * 100:.2f}% (How many predicted anomalies were real)\")\n",
        "    print(f\"Recall:    {recall * 100:.2f}% (How many real anomalies were caught)\")\n",
        "    print(f\"F1-Score:  {f1 * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"         Pred Normal  Pred Anomaly\")\n",
        "    print(f\"True Normal:   {cm[0][0]:>5}      {cm[0][1]:>10}\")\n",
        "    print(f\"True Anomaly:  {cm[1][0]:>5}      {cm[1][1]:>10}\")\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "\n",
        "# --- 4. Flask API for Serving ---\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = None\n",
        "\n",
        "def load_model():\n",
        "    \"\"\"Load the trained model from disk.\"\"\"\n",
        "    global model\n",
        "    try:\n",
        "        model = joblib.load(MODEL_FILE)\n",
        "        print(f\"Model {MODEL_FILE} loaded successfully for Flask app.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Model file '{MODEL_FILE}' not found.\")\n",
        "        print(\"Please run the script directly first to train and save the model.\")\n",
        "        model = None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        model = None\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict_anomaly():\n",
        "    \"\"\"\n",
        "    API endpoint to predict if new data is an anomaly.\n",
        "\n",
        "    Expects JSON payload:\n",
        "    {\n",
        "        \"features\": [1.2, 2.3]\n",
        "    }\n",
        "\n",
        "    Returns JSON response:\n",
        "    {\n",
        "        \"prediction\": \"normal\" | \"anomaly\"\n",
        "    }\n",
        "    or\n",
        "    {\n",
        "        \"error\": \"Error message\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return jsonify({\"error\": \"Model is not loaded.\"}), 500\n",
        "\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "\n",
        "        if 'features' not in data:\n",
        "            return jsonify({\"error\": \"Missing 'features' key in JSON payload.\"}), 400\n",
        "\n",
        "        features = data['features']\n",
        "\n",
        "        # Ensure features are in the correct format (list or 1D array)\n",
        "        if not isinstance(features, list) or len(features) != 2:\n",
        "            return jsonify({\"error\": \"Features must be a list of 2 numbers.\"}), 400\n",
        "\n",
        "        # Convert to 2D numpy array for sklearn prediction\n",
        "        features_np = np.array(features).reshape(1, -1)\n",
        "\n",
        "        # Get prediction (1 for normal, -1 for anomaly)\n",
        "        prediction_raw = model.predict(features_np)\n",
        "\n",
        "        # Convert to human-readable string\n",
        "        result = \"anomaly\" if prediction_raw[0] == -1 else \"normal\"\n",
        "\n",
        "        return jsonify({\"prediction\": result})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"An error occurred during prediction: {str(e)}\"}), 500\n",
        "\n",
        "# --- Main execution ---\n",
        "if __name__ == '__main__':\n",
        "    # Step 1: Train, evaluate, and save the model\n",
        "    train_and_evaluate_model()\n",
        "\n",
        "    # Step 2: Load the model for the API\n",
        "    load_model()\n",
        "\n",
        "    # Step 3: Run the Flask server\n",
        "    if model is not None:\n",
        "        print(\"\\nStarting Flask server... Access at http://127.0.0.1:5000\")\n",
        "        print(\"Test the API with:\")\n",
        "        print(\"curl -X POST -H \\\"Content-Type: application/json\\\" -d \\\"{\\\\\\\"features\\\\\\\": [0.1, 0.2]}\\\" http://127.0.0.1:5000/predict\")\n",
        "        print(\"curl -X POST -H \\\"Content-Type: application/json\\\" -d \\\"{\\\\\\\"features\\\\\\\": [8.0, 8.0]}\\\" http://127.0.0.1:5000/predict\")\n",
        "        app.run(debug=True, port=5000)\n",
        "    else:\n",
        "        print(\"\\nFlask server not started due to model loading failure.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic dataset...\n",
            "Training One-Class SVM model...\n",
            "Model trained and saved to one_class_svm_model.joblib\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Accuracy:  93.00%\n",
            "Precision: 89.09% (How many predicted anomalies were real)\n",
            "Recall:    98.00% (How many real anomalies were caught)\n",
            "F1-Score:  93.33%\n",
            "\n",
            "Confusion Matrix:\n",
            "         Pred Normal  Pred Anomaly\n",
            "True Normal:      44               6\n",
            "True Anomaly:      1              49\n",
            "---------------------------------\n",
            "Model one_class_svm_model.joblib loaded successfully for Flask app.\n",
            "\n",
            "Starting Flask server... Access at http://127.0.0.1:5000\n",
            "Test the API with:\n",
            "curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"features\\\": [0.1, 0.2]}\" http://127.0.0.1:5000/predict\n",
            "curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"features\\\": [8.0, 8.0]}\" http://127.0.0.1:5000/predict\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrAXWFMAP0qy",
        "outputId": "6e8afc3c-37d4-436d-96de-6393262d2edd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}