{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO46DSSC9htcH/vFsRuGi1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketanp23/scsd-ddm-class/blob/main/AdaBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eGAwXTO9ChBi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step we define a custom class called AdaBoost that will implement the AdaBoost algorithm from scratch.\n",
        "\n",
        "This class will handle the entire training process and predictions.\n",
        "\n",
        "The AdaBoost class is where we define the entire AdaBoost algorithm which consists of:\n",
        "\n",
        "Initializing model parameters like number of estimators, weights and models.\n",
        "\n",
        "Fitting the model to the training data.\n",
        "\n",
        "Making predictions using the trained model."
      ],
      "metadata": {
        "id": "WSVaInTkEiNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoost:\n",
        "    def __init__(self, n_estimators=50):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.alphas = []\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        w = np.ones(n_samples) / n_samples\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            model = DecisionTreeClassifier(max_depth=1)\n",
        "            model.fit(X, y, sample_weight=w)\n",
        "            predictions = model.predict(X)\n",
        "\n",
        "            err = np.sum(w * (predictions != y)) / np.sum(w)\n",
        "\n",
        "            alpha = 0.5 * np.log((1 - err) / (err + 1e-10))\n",
        "\n",
        "            self.models.append(model)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "            w *= np.exp(-alpha * y * predictions)\n",
        "            w /= np.sum(w)\n",
        "\n",
        "    def predict(self, X):\n",
        "        strong_preds = np.zeros(X.shape[0])\n",
        "\n",
        "        for model, alpha in zip(self.models, self.alphas):\n",
        "            predictions = model.predict(X)\n",
        "            strong_preds += alpha * predictions\n",
        "\n",
        "        return np.sign(strong_preds).astype(int)"
      ],
      "metadata": {
        "id": "y0M72g_8ElZ8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The constructor (__init__) initializes the number of weak models (n_estimators) to a list to store the alphas (self.alphas) and a list to store the weak classifiers (self.models)\n",
        "\n",
        "\n",
        "\n",
        "In the fit() method we:\n",
        "\n",
        "Sample Weights Initialization: w= np.ones(n_samples) / n_samples initializes all sample weights equally.\n",
        "\n",
        "Training the Weak Classifier: A DecisionTreeClassifier with max_depth =1 is trained using the current sample weights.\n",
        "\n",
        "Error Calculation: err = np.sum (w* ( predictions != y)) / np.sum(w) computes the weighted error of the classifier.\n",
        "\n",
        "Alpha Calculation: alpha = 0.5*np.log ((1-err) / (err+1e-10) ) calculates the classifier's weight (alpha).\n",
        "\n",
        "Updating Weights: Misclassified samples weights are increased using w *= np.exp(-alpha *y *predictions) and normalized with w /= np.sum(w)."
      ],
      "metadata": {
        "id": "GDvcMoLYEoXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        w = np.ones(n_samples) / n_samples\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            model = DecisionTreeClassifier(max_depth=1)\n",
        "            model.fit(X, y, sample_weight=w)\n",
        "            predictions = model.predict(X)\n",
        "\n",
        "            err = np.sum(w * (predictions != y)) / np.sum(w)\n",
        "\n",
        "            alpha = 0.5 * np.log((1 - err) / (err + 1e-10))\n",
        "\n",
        "            self.models.append(model)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "            w *= np.exp(-alpha * y * predictions)\n",
        "            w /= np.sum(w)"
      ],
      "metadata": {
        "id": "WYeGEcC_EtV0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the predict() method we combine the predictions of all weak classifiers using their respective alpha values to make the final prediction.\n",
        "\n",
        "strong_preds = np.zeroes(X.shape[0]) initializes an array of zeros to store the weighted sum of predictions from all weak classifiers.\n",
        "\n",
        "for model, alpha in zip(self.models, self.alphas) loops through each trained model and its corresponding alpha value.\n",
        "\n",
        "strong_preds += alpha * predictions adds the weighted prediction of each weak model to strong_preds\n",
        "\n",
        "np.sign(strong_preds) takes the sign of the sum to classify samples as 1 (positive class) or -1 (negative class)."
      ],
      "metadata": {
        "id": "bnj9S1jJE8dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self, X):\n",
        "        strong_preds = np.zeros(X.shape[0])\n",
        "\n",
        "        for model, alpha in zip(self.models, self.alphas):\n",
        "            predictions = model.predict(X)\n",
        "            strong_preds += alpha * predictions\n",
        "\n",
        "        return np.sign(strong_preds).astype(int)"
      ],
      "metadata": {
        "id": "0g9WYiabE_HI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are generating a synthetic dataset with 1000 samples and 20 features.\n",
        "\n",
        "Then, we split the data into training and testing sets. We initialize and train an AdaBoost classifier with 50 estimators.\n",
        "\n",
        "After training, we predict on the test set and evaluate the model using accuracy, precision, recall, F1 score, and ROC-AUC. The ROC-AUC is calculated with a fallback in case probability scores are not provided.\n",
        "\n",
        "Finally, we print all evaluation metrics."
      ],
      "metadata": {
        "id": "Ew79IYZaFFcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    adaboost = AdaBoost(n_estimators=50)\n",
        "    adaboost.fit(X_train, y_train)\n",
        "\n",
        "    predictions = adaboost.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, predictions)\n",
        "    except ValueError:\n",
        "        roc_auc = 'Undefined (requires probability scores)'\n",
        "\n",
        "    print(f\"Accuracy: {accuracy * 100}%\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"ROC-AUC: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cms1ZXtFFKKe",
        "outputId": "b46010fd-2bd6-43f2-f5e2-ae432c6c0fdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.0%\n",
            "Precision: 0.8364779874213837\n",
            "Recall: 0.8580645161290322\n",
            "F1 Score: 0.8471337579617835\n",
            "ROC-AUC: 0.839377085650723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performs well with:\n",
        "\n",
        "Accuracy of 84% meaning it makes correct predictions most of the time.\n",
        "\n",
        "It has good balance between precision (0.836) which makes accurate positive predictions.\n",
        "\n",
        "Recall (0.858) which means it catch most of the actual positive cases.\n",
        "The F1 score (0.847) combines these two measures\n",
        "\n",
        "ROC-AUC (0.839) show the model does a good job of telling the difference between the two classes.\n",
        "\n",
        "Overall these metrics indicate good performance."
      ],
      "metadata": {
        "id": "TYR0inR_Fufm"
      }
    }
  ]
}